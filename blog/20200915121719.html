<!DOCTYPE html>
<html>
  <head>
    <!-- meta --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1.0">
<link rel="icon" type="image/x-icon" href="/images/logo.png">
<link rel="stylesheet" type="text/css" href="/css/common.css">

<script type="text/javascript" src="/js/jquery-1.9.0.min.js"></script>
<script type="text/javascript" src="/js/google-code-prettify/prettify.js"></script>
<link  type="text/css" rel="stylesheet" href="/js/google-code-prettify/prettify.css"/>
<script>
  $(function(){
    $("pre").addClass("prettyprint");
    function init(event){
      prettyPrint();
    }
    if(window.addEventListener)window.addEventListener("load",init,false);
    else if(window.attachEvent)window.attachEvent("onload",init);
    
    $(".to-top").click(function() {
      $('body, html').animate({scrollTop: 0}, 300, 'linear');;
    });
  });
</script>

<!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-5YWD0EFVYR"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-5YWD0EFVYR');
</script>

<title> Calculation process to get the final output from the initial input by deep learning  - Perl AI Deep Learning Tutorial</title>
<meta name="description" content="I will explain the calculation process to obtain the final output from the initial input by deep learning.">
  </head>
  <body>
    <div class="container">
      <div class="header">
        <div class="header_main">
  <h1>
    <a href="/"><img src="/images/logo.png">Perl AI Deep Learning Tutorial</a>
  </h1>
</div>

      </div>
      <div class="main">
        <div class="content">
          <div class="entry">
  <div class="top">
    <!-- top -->
  </div>
  <div class="middle">
    <h2><a href="/blog/20200915121719.html"> Calculation process to get the final output from the initial input by deep learning </a></h2>
<p>
  I will explain the calculation process to obtain the final output from the initial input by deep learning.
</p>
<div style="width:calc(100% - 30px);margin:10px auto;">
  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4525414114581084"
       crossorigin="anonymous"></script>
  <!-- 最初の段落下 - ディスプレイ 横長 レスポンシブ -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-4525414114581084"
       data-ad-slot="2828858335"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


<p>
  As a premise, <a href="/blog/20200913103640.html"> calculation to find the sum of vectors</a> and <a href="/blog/20200914103640.html"> calculation to find the product of matrices</a> Please understand.
</p>
<h3> Relationship between input layer, hidden layer, and output layer </h3>
<p>
  In the explanation of deep learning, the figures of the input layer, the hidden layer, and the output layer are always shown. However, this diagram is a conceptual diagram and does not adequately represent the data structure in an actual program.
</p>
<p>
  The information you need to know when writing a program is:
</p>
<p>
  "Number of inputs" and "Number of outputs of hidden layer".
</p>
<pre>
* * * (Input. 3)

Hidden layer 0

* * * * * (Output of hidden layer 0. 5)

Hidden layer 1

* * * (Output of hidden layer 1. Three.)

Hidden layer 2

* * (Hidden layer 2 output. Two. This is the final output.)
</pre>
<p>
  All individual data is represented by 32-bit floating point. It is a float type in C language.
</p>
<h4> Number of inputs </h4>
<p>
  For a 28-pixel x 28-pixel monochrome image, there are 784 float-type inputs. Since the color depth can be expressed from 0 to 255, it can be expressed as a float type value. The float type is a floating point type, but you can also represent an integer by not using a decimal point.
</p>
<h4> Number of hidden layer outputs </h4>
<p>
  You decide the number of hidden layer outputs yourself. If there are 3 layers, the 0th layer is 100, the 1st layer is 150, the 2nd layer is 120, and so on.
</p>
<p>
  The number of neurons in the neural network corresponds to this number.
</p>
<h4> Number of outputs </h4>
<p>
  For example, in the case of pattern recognition, the number of outputs is 3 when A, B, and C are judged.
</p>
<p>
  The final number of outputs in the hidden layer is the final number of outputs. In the above example, the last 120 is the final number of outputs.
</p>
<p>
  So, if you decide the number of outputs of the last hidden layer, it will be the number of outputs.
</p>
<h3> Information on each layer of the hidden layer </h3>
<p>
  Next, I will write about the information of each layer of the hidden layer. Each layer of the hidden layer has parameters called weights and biases. This is to <a href="/blog/20200302113052.html"> convert m inputs to n outputs</a>.
</p>
<p>
  The weights are expressed as a matrix. Bias is expressed as a vector.
</p>
<h4> Calculation to obtain output from input using weight and bias </h4>
<p>
  Perl code that converts two inputs into three outputs using weights and biases. This is succinctly calculated using a matrix. Think of add_vec as a matrix sum and mul_mut as a matrix multiplication function.
</p>
<p>
  Think of the weights as a 3-by-2 column-major matrix.
</p>
<pre>
#Details of actual processing
$outputs-&gt;[0] = $weights-&gt;[0] * $inputs-&gt;[0] + $weights-&gt;[3] * $inputs-&gt;[1] + $biases-&gt;[0];
$outputs-&gt;[1] = $weights-&gt;[1] * $inputs-&gt;[0] + $weights-&gt;[4] * $inputs-&gt;[1] + $biases-&gt;[1];
$outputs-&gt;[2] = $weights-&gt;[2] * $inputs-&gt;[0] + $weights-&gt;[5] * $inputs-&gt;[1] + $biases-&gt;[2];

# Matrix representation
$outputs = add_vec (mul_mut ($weights, $inputs), $biases);
</pre>
<p>
  Looking at mathematical formulas can be confusing, but it's easy to think of them as simple multiplication, addition, and function calls.
</p>
<h3> How to determine the shape of the weight and bias parameters for each layer </h3>
<p>
  Write what determines the weight and bias parameters for each layer.
</p>
<p>
  It's simple: the number of inputs, the number of neurons in each layer of the hidden layer, and the number of outputs. Once this is decided, it will be decided automatically.
</p>
<p>
  In the above example, the input is 2 and the output is 3. Then the weight is a 3-by-2 matrix and the bias is a 3-length vector.
</p>
<p>
  With 784 inputs and 100 outputs, the weight is a 100-by-784 matrix and the bias is a 100-length vector.
</p>
<p>
  Weights and biases are dynamic, updated after learning is complete. Please refer to the following articles for the initial values ​​with good weight and bias.
</p>
<ul>
  <li> <a href="/blog/20200311113241.html"> How to set the initial values ​​of the parameters of each layer</a> </li>
</ul>
<h3> The position where the activation function is applied </h3>
<p>
  The <a href="/blog/20200902120907.html"> activation function</a> is applied to the output of each layer. The output to which the activation function is applied becomes the input of the next layer.
</p>
<pre>
# Apply activation function
my $new_inputs = [];
for (my $i = 0; $i &lt;@$outputs; $i ++) {
  $new_inputs-&gt;[$i] = activate_func ($outputs-&gt;[$i]);
}
</pre>
<h3> Get the final output from the initial input with deep learning </h3>
<p>
  Now, let's write a program in Perl that gets the final output from the initial input in deep learning. Use <a href="/blog/20200911102242.html"> ReLU</a> for the activation function.
</p>
<p>
  Weights and biases can be calculated automatically, but for the sake of convenience, they are written in solid.
</p>
<p>
  The number of inputs is 2, and the number of outputs of each hidden layer is "3, 2". The final output of the hidden layer is the final output.
</p>
<pre>
use strict;
use warnings;

my $first_inputs = [0.1, 0.2];

#Hidden layer weights and biases
my $layers = [
  #Hidden layer 0 layer (2 inputs to 3 outputs)
  {
    weights =&gt; [
      0.6, 0.2, 0.4,
      0.4, 0.3, 0.7
    ],,
    weights_rows_length =&gt; 3,
    weights_columns_length =&gt; 2,
    biases =&gt; [0.5, 0.2, 0.8]
  },
  # 1 hidden layer (3 inputs to 2 outputs)
  {
    weights =&gt; [
      0.8, 0.2, 0.2,
      0.2, 0.1, 0.6
    ],,
    weights_rows_length =&gt; 2,
    weights_columns_length =&gt; 3,
    biases =&gt; [0.5, 0.1]
  },
];;

# Get the final output from the initial input
my $inputs = $first_inputs;
my $outputs;
for (my $i = 0; $i &lt;@$layers; $i ++) {
  my $layer = $layers-&gt;[$i];
  
  # weight
  my $weights = $layer-&gt;{weights};
  my $weights_rows_length = $layer-&gt;{weights_rows_length};
  my $weights_columns_length = $layer-&gt;{weights_columns_length};
  
  #Bias
  my $biases = $layer-&gt;{biases};
  
  # Output = Weight Matrix * Input + Bias
  my $mul_weight_inputs = mul_mat ($weights, $weights_rows_length, $weights_columns_length, $inputs);
  $outputs = add_vec ($mul_weight_inputs, $biases);
  
  # Apply activation function
  my $activate_outputs = [];
  for (my $i = 0; $i &lt;@$outputs; $i ++) {
    $activate_outputs-&gt;[$i] = relu ($outputs-&gt;[$i]);
  }
  
  # Output to next input
  $inputs = $activate_outputs;
}

# Show final output 1.166 0.872
print "@$outputs\n";

#Activation function ReLU
sub relu {
  my ($x) = @_;
  
  my $relu = $x * ($x&gt; 0.0);
  
  return $relu;
}

#Sum of vectors
sub add_vec {
  my ($mul_weight_inputs, $biases) = @_;
  
  my $outputs = [];
  for (my $i = 0; $i &lt;@$mul_weight_inputs; $i ++) {
    $outputs-&gt;[$i] = $mul_weight_inputs-&gt;[$i] + $biases-&gt;[$i];
  }
  
  return $outputs;
}

# Matrix product (matrix and vector multiplication)
sub mul_mat {
  my ($weights, $weights_rows_length, $weights_columns_length, $inputs) = @_;
  
  my $inputs_rows_length = @$inputs;
  my $inputs_columns_length = 1;

  my $outputs = [];
  
  #Calculation of matrix product
  for (my $row = 0; $row &lt;$weights_rows_length; $row ++) {
    for (my $col = 0; $col &lt;$inputs_columns_length; $col ++) {
      for (my $incol = 0; $incol &lt;$weights_columns_length; $incol ++) {
        $outputs-&gt;[$row + $col * $inputs_rows_length]
         + = $weights-&gt;[$row + $incol * $weights_rows_length] * $inputs-&gt;[$incol + $col * $inputs_rows_length];
      }
    }
  }
  
  return $outputs;
}
</pre>

  </div>
  <div class="bottom">
    <h3>Associated Information</h3>

<div style="margin:10px 0">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4525414114581084"
     crossorigin="anonymous"></script>
<ins class="adsbygoogle"
     style="display:block"
     data-ad-format="autorelaxed"
     data-ad-client="ca-pub-4525414114581084"
     data-ad-slot="9163995495"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
</div>

  </div>
</div>

        </div>
        <div class="side">
          <div style="margin-bottom:30px">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4525414114581084"
     crossorigin="anonymous"></script>
<!-- ディスプレイ縦長 --><ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4525414114581084"
     data-ad-slot="4544919209"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
</div>

<div style="margin-bottom:30px;padding:0 8px;">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4525414114581084"
     crossorigin="anonymous"></script>
<ins class="adsbygoogle"
     style="display:block"
     data-ad-format="autorelaxed"
     data-ad-client="ca-pub-4525414114581084"
     data-ad-slot="9163995495"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
</div>

        </div>
      </div>
      <div class="footer">
        <div class="perlri_link">
  <a rel="nofollow" href="https://perlclub.net/en">Perl Club</a>
</div>

      </div>
    </div>
  </body>
</html>
