<!DOCTYPE html>
<html>
  <head>
    <!-- Google Automatic Advertising -->
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4525414114581084"
     crossorigin="anonymous"></script>

<!-- meta --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1.0">
<link rel="icon" type="image/x-icon" href="/images/logo.png">
<link rel="stylesheet" type="text/css" href="/css/common.css">

<script type="text/javascript" src="/js/jquery-1.9.0.min.js"></script>
<script type="text/javascript" src="/js/google-code-prettify/prettify.js"></script>
<link  type="text/css" rel="stylesheet" href="/js/google-code-prettify/prettify.css"/>
<script>
  $(function(){
    $("pre").addClass("prettyprint");
    function init(event){
      prettyPrint();
    }
    if(window.addEventListener)window.addEventListener("load",init,false);
    else if(window.attachEvent)window.attachEvent("onload",init);
    
    $(".to-top").click(function() {
      $('body, html').animate({scrollTop: 0}, 300, 'linear');;
    });
  });
</script>

<!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=G-5YWD0EFVYR"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-5YWD0EFVYR');
</script>

<title> What is the parameter update optimization algorithm?  - Perl AI Deep Learning Tutorial</title>
<meta name="description" content="The parameter update optimization algorithm updates the parameters of  weight and  bias. In some cases, it is an algorithm designed to reach a high percentage of correct answers quickly and also to have a high final percentage of correct answers.">
  </head>
  <body>
    <div class="container">
      <div class="header">
        <div class="header_main">
  <h1>
    <a href="/"><img src="/images/logo.png">Perl AI Deep Learning Tutorial</a>
  </h1>
</div>

      </div>
      <div class="main">
        <div class="content">
          <div class="entry">
  <div class="top">
    <!-- top -->
  </div>
  <div class="middle">
    <h2><a href="/blog/20201023083657.html"> What is the parameter update optimization algorithm? </a></H2>
<p>
  The parameter update optimization algorithm updates the parameters of <a href="/blog/20201015143424.html"> weight</a> and <a href="/blog/20201016143424.html"> bias</a>. In some cases, it is an algorithm designed to reach a high percentage of correct answers quickly and also to have a high final percentage of correct answers.
</p>
<div style="width:calc(100% - 30px);margin:10px auto;">
  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4525414114581084"
       crossorigin="anonymous"></script>
  <!-- 最初の段落下 - ディスプレイ 横長 レスポンシブ -->
  <ins class="adsbygoogle"
       style="display:block"
       data-ad-client="ca-pub-4525414114581084"
       data-ad-slot="2828858335"
       data-ad-format="auto"
       data-full-width-responsive="true"></ins>
  <script>
       (adsbygoogle = window.adsbygoogle || []).push({});
  </script>
</div>


<ul>
  <li> <a href="/blog/20201017123741.html"> Stochastic Gradient Descent Method --SGD</a> </li>
  <li> <a href="/blog/20201022083657.html"> Adam --Improved SGD</a> </li>
</ul>
<h3> What is Mini Batch SGD? </H3>
<p>
  In the explanation of this site, the stochastic gradient descent method includes mini-batch SGD, but the original meaning is that one with a batch size of 1 is called SGD, and one with multiple batch sizes is called mini-batch SGD. I call.
</p>
<h3> What is the gradient descent method? </H3>
<p>
  Gradient descent is a stochastic gradient descent that does not randomly sort the training data.
</p>
<p>
  Probabilistic means that the training data is randomly rearranged.
</p>
<h3> What is the steepest descent method? </H3>
<p>
  The steepest descent method is a gradient descent method in which the batch size is the same as the number of trainings.
</p>
<p>
  "Sudden descent" means that a parameter that causes a large change (large slope) to the loss function, which is an index of error, is updated by subtracting the value considering the learning rate from its magnitude.
</p>
<h3> How to understand </h3>
<p>
  How to understand the parameter update optimization algorithm.
</p>
<h4> Randomly sort the training data </​​h4>
<p>
  It is expressed by the word "stochastic".
</p>
<h4> Several batch sizes </h4>
<p>
  If the batch size is the same as the number of trainings, it is the steepest descent method, if there is one batch size, it is the gradient descent method (SDG), and if there are multiple batch sizes, it is the mini-batch SGD.
</p>
<h3> Batch size and parallelization </h3>
<p>
  The great thing about the mini-batch SDG is that it can be parallelized using threads and so on. This can improve performance.
</p>
<p>
  Since each learning is independent, the slope can be calculated independently.
</p>
<h3> Parameter update optimization algorithm that further improves the mini-batch SDG </h3>
<p>
  There is a parameter optimization algorithm that is an improvement over the mini-batch SDG.
</p>
<ul>
  <li> <a href="/blog/20201022083657.html"> Adam --Improved SGD</a> </li>
</ul>

  </div>
  <div class="bottom">
    <h3>Associated Information</h3>

<div style="margin:10px 0">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4525414114581084"
     crossorigin="anonymous"></script>
<ins class="adsbygoogle"
     style="display:block"
     data-ad-format="autorelaxed"
     data-ad-client="ca-pub-4525414114581084"
     data-ad-slot="9163995495"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
</div>

  </div>
</div>

        </div>
        <div class="side">
          <div style="margin-bottom:30px">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4525414114581084"
     crossorigin="anonymous"></script>
<!-- ディスプレイ縦長 --><ins class="adsbygoogle"
     style="display:block"
     data-ad-client="ca-pub-4525414114581084"
     data-ad-slot="4544919209"
     data-ad-format="auto"
     data-full-width-responsive="true"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
</div>

<div style="margin-bottom:30px;padding:0 8px;">
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4525414114581084"
     crossorigin="anonymous"></script>
<ins class="adsbygoogle"
     style="display:block"
     data-ad-format="autorelaxed"
     data-ad-client="ca-pub-4525414114581084"
     data-ad-slot="9163995495"></ins>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>
</div>

        </div>
      </div>
      <div class="footer">
        <div class="perlri_link">
  <a rel="nofollow" href="https://perlclub.net/en">Perl Club</a>
</div>

      </div>
    </div>
  </body>
</html>
