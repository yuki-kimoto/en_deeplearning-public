<!DOCTYPE html>
<html>
  <head>
    <!-- meta -->
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<link rel="icon" type="image/x-icon" href="/images/deeplearning-logo.png">
<link rel="stylesheet" type="text/css" href="/css/common.css">

<title>Entries - Perlディープラーニング入門 - 機械学習・深層学習の基礎の数学</title>
<meta name="description" content="Entries of Perlディープラーニング入門 - 機械学習・深層学習の基礎の数学">
  </head>
  <body>
    <div class="container">
      <div class="header">
        <h1>
  <a href="/">Perlディープラーニング入門 - 深層学習・機械学習の基礎数学</a>
</h1>

      </div>
      <div class="main">
        <div class="content">
          <div class="entry">
  <div class="top">
    <!-- top -->

  </div>
  <div class="middle">
    <h2><a href="/list.html">Entries</a></h2>
<ul>
  <li style="list-style:none;">
    <b>2021</b>
  </li>
  <li style="list-style:none">
    7/21 <a href="/blog/20210721085555.html">2021年度中高生世代向けAIプログラミング講座を開始しました</a>
  </li>
  <li style="list-style:none">
    5/10 <a href="/blog/20210510142804.html">SPVMを使ったディープラーニング高速化</a>
  </li>
  <li style="list-style:none;">
    <b>2020</b>
  </li>
  <li style="list-style:none">
    11/18 <a href="/blog/20201118093000.html">Perlのディープラーニングのライブラリ - AI::MXNet</a>
  </li>
  <li style="list-style:none">
    10/26 <a href="/blog/20201026095954.html">逆誤差伝播法 - バックプロパゲーション 書き始め</a>
  </li>
  <li style="list-style:none">
    10/23 <a href="/blog/20201023083657.html">パラメーター更新最適化アルゴリズムとは</a>
  </li>
  <li style="list-style:none">
    10/22 <a href="/blog/20201022083657.html">Adam - SGDを改善したパラメーター更新最適化アルゴリズム</a>
  </li>
  <li style="list-style:none">
    10/21 <a href="/blog/20201021085550.html">多段の関数の場合の傾きの求め方 - 合成関数の微分</a>
  </li>
  <li style="list-style:none">
    10/20 <a href="/blog/20201020085300.html">傾き(かたむき)とは - 微分係数</a>
  </li>
  <li style="list-style:none">
    10/19 <a href="/blog/20201019123741.html">tanh関数 - 活性化関数</a>
  </li>
  <li style="list-style:none">
    10/18 <a href="/blog/20201018123741.html">tanh関数の導関数 - 活性化関数の導関数</a>
  </li>
  <li style="list-style:none">
    10/17 <a href="/blog/20201017123741.html">確率的勾配降下法(SGD) - 重みとバイアスのパラメータの更新</a>
  </li>
  <li style="list-style:none">
    10/16 <a href="/blog/20201016143424.html">バイアスとは</a>
  </li>
  <li style="list-style:none">
    10/15 <a href="/blog/20201015143424.html">重みとは</a>
  </li>
  <li style="list-style:none">
    10/7 <a href="/blog/20201007144439.html">Xavierの初期値</a>
  </li>
  <li style="list-style:none">
    10/6 <a href="/blog/20201006144439.html">Heの初期値</a>
  </li>
  <li style="list-style:none">
    10/5 <a href="/blog/20201005144439.html">正規分布に従う乱数を求める</a>
  </li>
  <li style="list-style:none">
    10/2 <a href="/blog/20201002161518.html">softmax関数</a>
  </li>
  <li style="list-style:none">
    10/1 <a href="/blog/20201001161518.html">ReLU関数の導関数 - 活性化関数の導関数</a>
  </li>
  <li style="list-style:none">
    9/29 <a href="/blog/20200929161518.html">列優先の行列を作成する</a>
  </li>
  <li style="list-style:none">
    9/28 <a href="/blog/20200928161518.html">行列とは</a>
  </li>
  <li style="list-style:none">
    9/27 <a href="/blog/20200927161518.html">softmax関数とクスエントロピー誤差の合成関数の導関数</a>
  </li>
  <li style="list-style:none">
    9/26 <a href="/blog/20200926161518.html">ピュアPerlで書いたMNIST手書き認識ディープラーニング</a>
  </li>
  <li style="list-style:none">
    9/24 <a href="/blog/20200924123308.html">ベクトルの内積の計算</a>
  </li>
  <li style="list-style:none">
    9/23 <a href="/blog/20200923123308.html">学習率とは</a>
  </li>
  <li style="list-style:none">
    9/22 <a href="/blog/20200922123308.html">逆誤伝播法 - 逆誤差伝播法</a>
  </li>
  <li style="list-style:none">
    9/21 <a href="/blog/20200921123308.html">勾配(こうばい)とは</a>
  </li>
  <li style="list-style:none">
    9/20 <a href="/blog/20200920123308.html">シグモイド関数の導関数</a>
  </li>
  <li style="list-style:none">
    9/19 <a href="/blog/20200919123308.html">導関数とは</a>
  </li>
  <li style="list-style:none">
    9/17 <a href="/blog/20200917123308.html">転置行列を求める</a>
  </li>
  <li style="list-style:none">
    9/16 <a href="/blog/20200916101844.html">期待される出力を確率で表現する</a>
  </li>
  <li style="list-style:none">
    9/15 <a href="/blog/20200915121719.html">ディープラーニングで初期入力から最終出力を得る計算過程</a>
  </li>
  <li style="list-style:none">
    9/14 <a href="/blog/20200914103640.html">行列の積の計算</a>
  </li>
  <li style="list-style:none">
    9/13 <a href="/blog/20200913103640.html">ベクトルの和を求める</a>
  </li>
  <li style="list-style:none">
    9/12 <a href="/blog/20200912123308.html">行列の和を求める</a>
  </li>
  <li style="list-style:none">
    9/11 <a href="/blog/20200911102242.html">ReLU関数 - 活性化関数</a>
  </li>
  <li style="list-style:none">
    9/10 <a href="/blog/20200910120907.html">二乗和誤差を求める - 損失関数</a>
  </li>
  <li style="list-style:none">
    9/9 <a href="/blog/20200909120907.html">MNISTラベル情報を読み込む</a>
  </li>
  <li style="list-style:none">
    9/8 <a href="/blog/20200908120907.html">Perl+ディープラーニングで手書き文字認識</a>
  </li>
  <li style="list-style:none">
    9/7 <a href="/blog/20200907120907.html">MNIST画像情報を読み込む</a>
  </li>
  <li style="list-style:none">
    9/6 <a href="/blog/20200906120907.html">訓練データをランダムにシャッフルする</a>
  </li>
  <li style="list-style:none">
    9/5 <a href="/blog/20200905120907.html">隠れ層におけるニューロンの数を表現する</a>
  </li>
  <li style="list-style:none">
    9/4 <a href="/blog/20200904120907.html">エポックという単位は訓練データを一巡することを指す</a>
  </li>
  <li style="list-style:none">
    9/3 <a href="/blog/20200903120907.html">シグモイド関数 - 活性化関数</a>
  </li>
  <li style="list-style:none">
    9/2 <a href="/blog/20200902120907.html">活性化関数とは</a>
  </li>
  <li style="list-style:none">
    9/1 <a href="/blog/20200901120907.html">損失関数とは</a>
  </li>
  <li style="list-style:none">
    8/31 <a href="/blog/20200831120907.html">クロスエントロピー誤差を求める - 損失関数</a>
  </li>
  <li style="list-style:none">
    8/30 <a href="/blog/20200830120907.html">バッチサイズとは - オンライン学習、ミニバッチ学習、バッチ学習</a>
  </li>
  <li style="list-style:none">
    8/29 <a href="/blog/20200829120907.html">行列の差を求める</a>
  </li>
  <li style="list-style:none">
    8/28 <a href="/blog/20200828120907.html">ベクトルの差を求める</a>
  </li>
  <li style="list-style:none">
    3/11 <a href="/blog/20200311113241.html">各層の重みとバイアスのパラメーターの初期値の設定方法</a>
  </li>
  <li style="list-style:none">
    3/6 <a href="/blog/20200306113052.html">出力層における計算</a>
  </li>
  <li style="list-style:none">
    3/2 <a href="/blog/20200302113052.html">中間層における計算 - m個の入力をn個の出力に変換する</a>
  </li>
</ul>

  </div>
  <div class="bottom">
    <!-- bottom -->

<h3>Perlで学ぶディープラーニング入門のご紹介</h3>

<div class="youtube_block">
  <div class="youtube">
    <iframe width="560" height="315" src="https://www.youtube.com/embed/dTKY0kor50A" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  </div>
</div>

<div style="text-align:center;margin-top:30px;font-weight:bold;font-size:22px;">
Perlテキスト処理と正規表現の基礎を学ぶ
</div>
<div style="text-align:center;margin-top:30px;">
  <a href="https://www.perlri.com/book/perl_text_essense"><img alt="テキスト処理" src="https://tutorial.perlzemi.com/images/book/perl_text_essence.jpg" style="width:220px;margin:0 auto;"></a><br><a href="https://www.perlri.com/book/perl_text_essense" style="font-size:20px;">Perlテキスト処理のエッセンス</a>
</div>

  </div>
</div>

        </div>
        <div class="side">
          <!-- side -->
<div class="side-list">
  <div class="side-list-title">
    講座作成
  </div>
  <ul>
    <li style="text-align:center;padding-left:0"><a href="http://www.perlri.com/"><img width="110" src="https://tutorial.perlzemi.com/images/kaeru_w_01.png"><br>Perl元気塾</a></li>
  </ul>
  <div class="side-list-title">
    コンテンツ
  </div>
  <ul>
    <li><a href="/list.html">新着情報</a></li>
  </ul>
  <div class="side-list-title" style="margin-top:30px;">
    Perlテキスト処理のエッセンス
  </div>
  <ul>
    <li style="text-align:center;">
      <a rel="nofollow" href="https://www.perlri.com/book/perl_text_essense"><img alt="テキスト処理" src="https://tutorial.perlzemi.com/images/book/perl_text_essence.jpg" width="160"></a><br>
      <a rel="nofollow" href="https://www.perlri.com/book/perl_text_essense">Perlテキスト処理のエッセンス</a><br>
    </li>
  </ul>
</div>

        </div>
      </div>
      <div class="footer">
        <div class="what_is_this_site">
  <div class="inside">
    <b>ディープラーニングを使ったAI</b>を<a href="https://tutorial.perlzemi.com/">Perl</a>で学ぶ講座です。ライブラリを使わずに、if文とfor文とソフトウェアと数学の基本的な知識(高度なものではなく)があれば、学べるように構成しています。<br>実用においては、ディープラーニングのC++で書かれたMXNetライブラリの機能をPerlから呼び出せる、<a href="https://metacpan.org/pod/AI::MXNet">AI::MXNet</a>というモジュールによって提供されています。AI::MXNetは、画像判別、自然言語処理、画像生成などのディープラーニングの応用にも対応しています。<br>Perlでは、数値計算や配列演算の性能が足りない場合は、<a href="https://c.perlzemi.com/">C言語</a>やC++で書かれたライブラリを<a href="https://bind.perlzemi.com/">バインディング</a>できます。<br>誤解が多いですが、<a href="https://datascience.perlzemi.com/">データ分析</a>においては、ディープラーニングによるAI(あるいは学習アルゴリズム)は、非常に限られた分野での応用で、精度が高くなる場合は限定されています。
  </div>
</div>

<div class="perlri_link">
  <a href="http://www.perlri.com">
    プログラミングスクール<br>Perl元気塾
  </a>
</div>

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4525414114581084"
     crossorigin="anonymous"></script>
      </div>
    </div>
  </body>
</html>
